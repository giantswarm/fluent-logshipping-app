# Default values for fluent-logshipping-app.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

# clusterID is dynamic environment value, calculated after cluster creation
# applies only to Giant Swarm clusters
clusterID: clusterID

project:
  branch: "[[ .Branch ]]"
  commit: "[[ .SHA ]]"

registry:
  domain: docker.io

fluentbit:
  priorityClass:
    customEnabled: true
    name: fluentbit

  port: 5170
  protocol: TCP

  # For systemd sshd logs it needs root
  userID: 0
  # For systemd sshd logs it needs root
  groupID: 0

  image:
    name: giantswarm/fluent-bit
    # -- Overrides the image tag whose default is the chart's appVersion
    # This image fixes some systemd issues fixed in 1.8.x and adds the aws-for-fluent-bit cloudwatch plugin to be able to template cloudwatch log stream names.
    tag: "1.9.8-aws-plugins"

  logLevel: info
  flushFrequencyInSeconds: 5
  backlogMemLimit: "50M"
  memBufferLimit: "10MB"
  storageMaxChunksUp: 128

  inputStorageTypes:
    audit: "memory"
    container: "memory"
    sshd: "memory"
    syslog: "memory"

serviceAccount:
  annotations: {}

outputs:
  inputLogTypes: &logTypes
  - sshd
  - containers
  - syslog
  - audit
  aws:
    kiam: false
    role: ""
    region: ""
    credentials:
      awsAccessKey: ""
      awsSecretKey: ""
    cloudWatch:
      enabled: false
      inputLogTypes: *logTypes
      logGroupName: "my-cluster"
      logStreamName: "example-stream"
      logRetentionDays: -1
    S3:
      enabled: false
      inputLogTypes: *logTypes
      bucketName: "my-cluster-logs"
      bucketPathPrefix: ""
      endpoint: ""
      totalFileSize: "100M"
      s3_object_key_format: "/$TAG/%Y/%m/%d/%H/%M/%S"

  azure:
    logAnalytics:
      enabled: false
      inputLogTypes: *logTypes
      workspaceId: ""
      sharedKey: ""
      customLogs:
        audit:
          ssh:
            name: SshAuditLogs
          kubernetes:
            name: KubernetesAuditLogs
        containers:
          name: KubernetesContainerLogs
        syslog:
          name: KubernetesSyslog

  elasticsearch:
    enabled: false
    inputLogTypes: *logTypes
    host: ""
    port: 9200
    path: "/"
    tlsEnabled: true
    sslVerify: true
    secured: false
    user: ""
    password: ""
    indices:
      audit:
        ssh:
          name: audit-ssh
        kubernetes:
          name: audit-kubernetes
      containers:
        name: kubernetes
      syslog:
        name: syslog

  tcp:
    enabled: false
    host: ""
    port: ""
    # Specify the data format to be printed. Supported formats are msgpack, json, json_lines and json_stream.
    format: json
    # Specify the name of the time key in the output record. To disable the time key just set the value to false.
    json_date_key: date
    # Specify the format of the date. Supported formats are double, epoch and iso8601 (eg: 2018-05-30T09:39:52.000681Z)
    json_date_format: double
    inputLogTypes: *logTypes
    # This output currently only supports the forwarding of syslog messages.
    indices:
      syslog:
        name: syslog

  extraOutputConfig: ""

extraFilters: ""

giantswarm:
  monitoring:
    enabled: true

# Enable Kyverno PolicyException
kyvernoPolicyExceptions:
  enabled: true
  namespace: giantswarm

# Tolerate all nodes with NoSchedule taints
tolerations:
  - operator: "Exists"
    effect: "NoSchedule"

resources:
  limits:
    memory: 200Mi
  requests:
    cpu: 500m
    memory: 100Mi

verticalPodAutoscaler:
  enabled: true
